B2.2 guide 

A. Prepare training and validation datasets

A.1. Divide whole training in training and validation

cat training_tweets_es_clean.txt | awk '{ if (NR%5==0) print > "val_tweets_es_clean.txt"; else print > "tr_tweets_es_clean.txt"; }'

A.2. Obtain training and validation labels

cut -d ":" -f 7 training_truth_es.txt | awk '{ if (NR%5==0) print > "val_truth_es.txt"; else print > "tr_truth_es.txt"; }'

A.3. Separate validation files

cat val_tweets_es_clean.txt | awk '{ n="000"NR; n=substr(n,length(n)-3); f="val_tweets_es_clean_"n".txt"; print > f; close(f); }'

B. Search for the best model (to be repeated for different models)

B.1. Obtain FEMALE and MALE models from "tr_tweets_es_clean.txt" and "tr_truth_es.txt" (see slides 25 and 26)

B.2. For each "val_tweets_es_clean_XXXX.txt"
     - Generate sentence
     - Generate FEMALE and MALE automaton
     - Compose sentence automaton with FEMALE and MALE general models and obtain FEMALE and MALE probabilities
     - Obtain assigned label

for f in val_tweets_es_clean_*.txt ; do
  ess=`cat $f | awk '{print "<s> "$0" </s>"}'`
  echo $ess | str2fst.pl vocf_es | fstcompile --isymbols=vocf_es --osymbols=vocf_es --keep_isymbols --keep_osymbols > essf.fst
  echo $ess | str2fst.pl vocm_es | fstcompile --isymbols=vocm_es --osymbols=vocm_es --keep_isymbols --keep_osymbols > essm.fst
  fstcompose essf.fst female_es.fst | fstshortestpath | fstrmepsilon | fstprint | LC_NUMERIC=C awk '{s+=$NF;} END{print(s);}' > auxf
  fstcompose essm.fst male_es.fst | fstshortestpath | fstrmepsilon | fstprint | LC_NUMERIC=C awk '{s+=$NF;} END{print(s);}' > auxm
  paste auxf auxm | LC_NUMERIC=C awk '{if ($1<$2) print "FEMALE"; else print "MALE";}'
done > val_tweets_es_clean_classification.txt

B.3. Calculate accuracy

paste val_truth_es.txt val_tweets_es_clean_classification.txt | awk '{if ($1==$2) a++;} END{print(a*100/NR);}'

C. Prepare final blind test

C.1. Download blind test from the PoliformaT task ("test_tweets_es.txt")

C.2. Clean blind test set

clean-tweets.sh test_tweets_es.txt > test_tweets_es_clean.txt

C.3. As A.3 but for "test_tweets_es_clean.txt"

D. Train final models

D.1. Select parameters for the final model (n-gram degree, discounts, ...) based on best result in step B

D.2. Obtain whole training labels

cut -d ":" -f 7 training_truth_es.txt > training_truth_es_clean.txt

D.3. As B.1 but with "training_tweets_es_clean.txt" and "training_truth_es_clean.txt"

E.  Classify final blind test

E.1. As B.2 but for "test_tweets_es_clean_XXXX.txt"

E.2. Upload classification file result ("test_tweets_es_clean_classification.txt")
